# Setting Up a PySpark Notebook Using Docker

This Github is part of an introductionairy training for PySpark. In this training we will discuss Spark and it's surrounding concepts. We will be using the Python language to interact with Spark.

## Learning goals
- Introduction to Python and it's syntax
- Learn the basics of Spark
    - What is a distributed system? And how does it affect fault tollerance
    - What is a RDD?
    - What is a dataframe?
- Basic dataframe operations



## Intro to PySpark

To introduce PySpark we are Using Coder2J's great [PySpark Tutorial.](https://github.com/coder2j/pyspark-tutorial/tree/main).

Our main goals are to get a feel for how to get started with Spark, Python syntax and their functionalities.


## To get started with the excercises

1. Start the Docker desktop application
2. Go to the [Docker Setup](https://github.com/JasperBrancart/Pyspark-Sessie/blob/main/SetupDocker.md) page and follow the steps

## Excercises

To introduce PySpark we are usingthe Urban Institutes [PySpark Tutorial.]([https://github.com/coder2j/pyspark-tutorial/tree/main](https://github.com/UrbanInstitute/pyspark-tutorials/)).
